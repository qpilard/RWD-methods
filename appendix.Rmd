# (APPENDIX) Appendix {.unnumbered}

# Installed packages {#r-packages}

This is the R packages installed and loaded to write this book, with the use of the pacman library.

```{r installed_packages, message=FALSE, warning=FALSE}
#Install pacman library
if (!require("pacman")) install.packages("pacman", repos = "https://cloud.r-project.org")

# Load pacman
library(pacman)

# Install and load the packages
pacman::p_load(
  cobalt,
  WeightIt,
  gtsummary,
  smd,
  survey,
  ggplot2,
  dplyr,
  ggpubr,
  cardx,
  broom,
  broom.helpers,
  survminer,
  survival,
  dagitty,
  ggdag,
  kable,
  kableExtra
)
```

# R code of the simulated dataset {#r-code}

This is the R code to reproduce the motivating example:

```{r simulation}
# Ensure reproducibility
set.seed(42)  

# Number of patients
N <- 800

# Patient IDs
ID <- 1:N

# Generation of base variables
AGE <- pmax(pmin(round(rnorm(N, mean = 32, sd = 6.19)), 80), 18)  # Age bounded between 18 and 80
GENDER <- sample(0:1, N, replace = TRUE)  # Binary gender variable
SOCIO_ECO <- sample(1:5, N, replace = TRUE)  # Socioeconomic status categories
SOCIO_ECO_2 <- as.numeric(SOCIO_ECO == 2)  # Dummy variable for SOCIO_ECO == 2
SOCIO_ECO_3 <- as.numeric(SOCIO_ECO == 3)  # Dummy variable for SOCIO_ECO == 3
SOCIO_ECO_4 <- as.numeric(SOCIO_ECO == 4)  # Dummy variable for SOCIO_ECO == 4
SOCIO_ECO_5 <- as.numeric(SOCIO_ECO == 5)  # Dummy variable for SOCIO_ECO == 5
BECK <- pmax(pmin(round(rnorm(N, mean = 30, sd = 9.33)), 63), 0)  # Beck score bounded between 0 and 63

# Utility function to generate binary variables based on a logistic model
logit_prob <- function(eta) {
  1 / (1 + exp(-eta))  # Logistic function
}

# Coefficients for predictors
coefficients <- list(
  intercept = -1.5,      # Base intercept for treatment assignment
  age = -0.04,           # Negative effect of age
  gender = -0.3,         # Negative effect of gender (e.g., Female is less likely to be assigned)
  beck = 0.1,            # Positive effect of Beck score
  socio_eco_2 = -0.10,   # Negative effect for SOCIO_ECO_2
  socio_eco_3 = -0.12,   # Negative effect for SOCIO_ECO_3
  socio_eco_4 = -0.18,   # Negative effect for SOCIO_ECO_4
  socio_eco_5 = -0.25    # Stronger negative effect for SOCIO_ECO_5
)

# Generation of initial treatment (TREAT)
eta_treat <- coefficients$intercept + 
  coefficients$age * AGE + 
  coefficients$gender * GENDER +
  coefficients$beck * BECK + 
  coefficients$socio_eco_2 * SOCIO_ECO_2 +
  coefficients$socio_eco_3 * SOCIO_ECO_3 + 
  coefficients$socio_eco_4 * SOCIO_ECO_4 +
  coefficients$socio_eco_5 * SOCIO_ECO_5

TREAT <- rbinom(N, 1, logit_prob(eta_treat + rnorm(N)))  # Simulating treatment assignment

# Coefficients for treatment delay based on treatment status
coefficients_delay <- list(
  sertralex = list(
    intercept = 10,      # Base parameter for delay
    age = -0.02,         # Negative effect of age on delay
    gender = 0.1,        # Positive effect of gender on delay
    beck = -0.05,        # Negative effect of Beck score on delay
    socio_eco_2 = 0.2,
    socio_eco_3 = 0.15,
    socio_eco_4 = 0.1,
    socio_eco_5 = 0.05
  ),
  duloxyn = list(
    intercept = 15,
    age = -0.02,
    gender = 0.1,
    beck = -0.05,
    socio_eco_2 = 0.2,
    socio_eco_3 = 0.15,
    socio_eco_4 = 0.1,
    socio_eco_5 = 0.05
  )
)

# Initialization of TIME_TO_TREAT variable
TIME_TO_TREAT <- numeric(N)

# Generation of treatment initiation delays
for (i in 1:N) {
  # Select appropriate coefficients
  delay_coeffs <- if (TREAT[i] == 1) {
    coefficients_delay$duloxyn
  } else {
    coefficients_delay$sertralex 
  }
  
  # Compute the mean
  linear_pred <- delay_coeffs$intercept +
    delay_coeffs$age * AGE[i] +
    delay_coeffs$gender * GENDER[i] +
    delay_coeffs$beck * BECK[i] +
    delay_coeffs$socio_eco_2 * SOCIO_ECO_2[i] +
    delay_coeffs$socio_eco_3 * SOCIO_ECO_3[i] +
    delay_coeffs$socio_eco_4 * SOCIO_ECO_4[i] +
    delay_coeffs$socio_eco_5 * SOCIO_ECO_5[i]
  
  # Generate time from a normal distribution
  TIME_TO_TREAT[i] <- round(rnorm(n = 1, mean = linear_pred + rnorm(n = 1), sd = 2.5), 0)
}

# Generation of relapse (EVENT) and time until relapse (TIME_TO_EVENT) in days
base_hazard <- 0.005  # Baseline hazard rate
EVENT <- numeric(N)
TIME_TO_EVENT <- numeric(N)
max_follow_up <- 365  # Maximum follow-up duration in days
coefficients <- list(
  intercept = -4,       # Base intercept for event hazard
  age = -0.01,          # Younger individuals are more likely to experience PDD                      
  gender = 0.1,         # Women are more likely to experience PDD                   
  socio_eco_2 = -0.05,  # Lower SES is more likely to experience PDD             
  socio_eco_3 = -0.10,             
  socio_eco_4 = -0.15,            
  socio_eco_5 = -0.20,            
  beck = 0.2,           # Higher Beck score increases the likelihood of PDD                    
  treat = -0.2          # Protective effect of Duloxyn                
)

for (i in 1:N) {
  eta_event <- coefficients$intercept + 
    coefficients$age * AGE[i] + 
    coefficients$gender * GENDER[i] +
    coefficients$beck * BECK[i] + 
    coefficients$socio_eco_2 * SOCIO_ECO_2[i] +
    coefficients$socio_eco_3 * SOCIO_ECO_3[i] + 
    coefficients$socio_eco_4 * SOCIO_ECO_4[i] +
    coefficients$socio_eco_5 * SOCIO_ECO_5[i] + 
    coefficients$treat * TREAT[i]
  
  adjusted_hazard <- base_hazard * exp(eta_event)  # Adjust hazard rate
  
  # Generate time to event in days
  TIME_TO_EVENT[i] <- round(rexp(1, rate = adjusted_hazard), 0)
  
  # Ensure EVENT only occurs within 365 days
  if (TIME_TO_EVENT[i] < max_follow_up) {
    EVENT[i] <- 1
  } else {
    EVENT[i] <- 0
  }
  
  # Ensure TIME_TO_EVENT doesn't exceed the maximum follow-up period
  TIME_TO_EVENT[i] <- min(TIME_TO_EVENT[i], max_follow_up)
  
}

# Organize data in a data frame
data <- data.frame(ID, AGE, GENDER, SOCIO_ECO, BECK, TREAT, TIME_TO_EVENT, EVENT, TIME_TO_TREAT)

# Filter data based on conditions
data <- data %>%
  filter(TIME_TO_EVENT > TIME_TO_TREAT & TIME_TO_TREAT < 30 & TIME_TO_EVENT > 0)

# Recategorize variables
data$GENDER <- factor(data$GENDER, levels = c(0, 1), labels = c("Male", "Female"))
data$SOCIO_ECO <- factor(data$SOCIO_ECO, levels = c(1, 2, 3, 4, 5), labels = c("Very low", "Low", "Moderate", "High", "Very high"))
data$TREAT <- factor(data$TREAT, levels = c(0, 1), labels = c("Sertralex", "Duloxyn"))

```

# ICH E9 (R1) addendum {#ich}

In 2020, the International Council for Harmonisation of Technical Requirements for Pharmaceuticals for Human Use (ICH) released the E9 (R1) addendum, which aims to guide practice regarding estimands and sensitivity analyses in clinical trials, moving beyond traditional ITT and PP analyses [@noauthor_ich_1998].

An estimand provides a clear definition of the treatment effect that reflects the clinical question posed by a specific trial objective. Its formulation is based on five attributes: treatment, population, variable of interest (endpoint), intercurrent event handling, and summary measure. The concept of intercurrent events, introduced in this framework, refers to events occurring after treatment initiation. Five strategies exist for handling intercurrent events, including treatment policy, while on treatment, hypothetical, composite approaches, and principal stratum strategy [@lawrance_what_2020; @roca_2024].

In our example, we reformulate the ITT and PP questions as suggested in the framework:

-   ITT: "In patients diagnosed with PDD, what is the effect of Duloxyn compared to Sertralex on the time to relapse from the date of diagnosis, over a one-year follow-up period or until death (whichever occurs first), regardless of study treatment discontinuation?" (this follows the treatment policy approach to handle treatment discontinuation).

-   PP: "In patients diagnosed with PDD, what is the effect of Duloxyn compared to Sertralex on the time to relapse from the date of diagnosis, over a one-year follow-up period or until death, or treatment discontinuation (whichever occurs first)?" (this follows the principal stratum strategy to handle treatment discontinuation).

# DAG of the simulated dataset {#dag}

This is the DAG associated with the simulation process:

```{r dag, echo=FALSE, message=FALSE}
# Define the DAG structure in Dagitty
dag_data <- dagitty("dag {
  RELAPSE [outcome]
  TREAT [exposure]
  Z
  TREAT -> RELAPSE
  Z -> RELAPSE
  Z -> TREAT
}")

# Define coordinates for the DAG layout
coords <- list(
  x = c(RELAPSE = 5.507, TREAT = -3.720, Z = -3.720),
  y = c(RELAPSE = 0.377, TREAT = 2.933, Z = -2.734)
)

coord_df <- coords2df(coords)
coordinates(dag_data) <- coords2list(coord_df)

# Plot the DAG using ggdag
ggdag_status(dag_data, 
             text_size = 2.5)+
  theme_dag()

```

For simplicity, Z represents the confounders measured at baseline, which include age, gender, socioeconomic status, and the Beck score.

# Causal inference estimand {#causal}

A causal estimand is a description of the quantity that is to be estimated. In the context of RWD, methods such as matching or weighting imply the selection of an estimand. Among these, two estimands are typically of interest: the average treatment effect in the treated (ATT) and the average treatment effect in the population (ATE).

The ATT is considered when assessing the effect of a treatment among individuals who are likely to receive it (e.g., when comparing a new drug to a placebo or standard of care). In our example, the research question would be framed as: what is the treatment effect among patients likely to receive Duloxyn? This includes individuals with characteristics similar to those receiving Sertralex, while individuals with characteristics unique to Duloxyn would be excluded from the analysis. This estimator typically involves pair matching statistical methods [@greifer_choosing_2023; @heiss_demystifying_nodate].
